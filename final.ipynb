{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.subplots\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "REMOVE_INTERNATIONAL = True\n",
    "INTERNATIONAL_LABEL = \"International\"\n",
    "\n",
    "PLOTS_PATH = \"plots\"\n",
    "PLOTS_PATH_PLT = os.path.join(PLOTS_PATH, \"plt\")\n",
    "PLOTS_PATH_PX = os.path.join(PLOTS_PATH, \"px\")\n",
    "PLOTS_PATH_HTML = os.path.join(PLOTS_PATH, \"html\")\n",
    "\n",
    "FIGURE_WIDTH = 800\n",
    "FIGURE_HEIGHT = 600\n",
    "\n",
    "for path in [PLOTS_PATH_PLT, PLOTS_PATH_PX, PLOTS_PATH_HTML]: \n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article continent labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continents = pd.read_csv(os.path.join(\"Data\", \"continents.csv\"))\n",
    "\n",
    "if REMOVE_INTERNATIONAL:\n",
    "    labeled_articles_all_count = len(df_continents)\n",
    "    df_continents = df_continents[df_continents.continent != INTERNATIONAL_LABEL]\n",
    "    labeled_articles_count = len(df_continents)\n",
    "    print(f\"Removing articles labeled as {INTERNATIONAL_LABEL}, Removed articles: {labeled_articles_all_count - labeled_articles_count}\")\n",
    "\n",
    "display(df_continents.head())\n",
    "print(\"Size:\", df_continents.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories = pd.read_csv(\n",
    "    os.path.join(\"Data\", \"wikispeedia_paths-and-graph\", \"categories.tsv\"),\n",
    "    delimiter=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"article\", \"category\"],\n",
    "    skip_blank_lines=True,\n",
    "    comment=\"#\",\n",
    "    encoding=\"UTF-8\"\n",
    ")\n",
    "\n",
    "main_categories = []\n",
    "for category in df_categories[\"category\"].values:\n",
    "    main_categories.append(category.split(\".\")[1])\n",
    "\n",
    "df_categories[\"categoryMain\"] = main_categories\n",
    "\n",
    "display(df_categories.head())\n",
    "print(\"Size:\", df_categories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continents_categories = pd.merge(df_continents, df_categories, on=\"article\")\n",
    "\n",
    "display(df_continents_categories.head())\n",
    "print(\"Size:\", df_continents_categories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = df_continents_categories[[\"article\", \"continent\"]].drop_duplicates()\n",
    "df_articles = pd.merge(df_articles, df_continents_categories.groupby(\"article\")[\"categoryMain\"].apply(list).reset_index(), on=\"article\")\n",
    "\n",
    "display(df_articles.head())\n",
    "print(\"Size:\", df_articles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaintext_path = os.path.join(\"Data\", \"plaintext_articles\")\n",
    "\n",
    "word_counts = []\n",
    "for article_name in df_articles.article:\n",
    "    file_path = os.path.join(plaintext_path, article_name + \".txt\")\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "\n",
    "        _ = file.readline() # Skip the first line because it contains the word #copyright\n",
    "        content = file.read()\n",
    "\n",
    "    content = content[:re.search(\"Retrieved from\", content).start(0)]\n",
    "    word_counts.append(len(content.split()))\n",
    "\n",
    "df_articles[\"length\"] = word_counts\n",
    "\n",
    "display(df_articles.head())\n",
    "print(\"Size:\", df_articles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pagerank = pd.read_csv(os.path.join(\"Data\", \"page_rank.csv\"))\n",
    "\n",
    "display(df_pagerank.head())\n",
    "print(\"Size:\", df_pagerank.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths_finished = pd.read_csv(\n",
    "    os.path.join(\"Data\", \"wikispeedia_paths-and-graph\", \"paths_finished.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"rating\"],\n",
    "    skip_blank_lines=True,\n",
    "    comment=\"#\"\n",
    ")\n",
    "df_paths_unfinished = pd.read_csv(\n",
    "    os.path.join(\"Data\", \"wikispeedia_paths-and-graph\", \"paths_unfinished.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"target\", \"motif\"],\n",
    "    skip_blank_lines=True,\n",
    "    comment=\"#\"\n",
    ")\n",
    "\n",
    "df_paths_finished[\"backclicks\"] = df_paths_finished[\"path\"].apply(lambda x: x.count(\"<\"))\n",
    "df_paths_finished[\"pathSteps\"] = df_paths_finished[\"path\"].apply(lambda x: x.count(\";\") + 1)\n",
    "df_paths_finished[\"uniqueArticles\"] = df_paths_finished[\"pathSteps\"] - df_paths_finished[\"backclicks\"]\n",
    "df_paths_finished[\"path\"] = df_paths_finished[\"path\"].apply(lambda x: x.split(\";\"))\n",
    "df_paths_finished[\"start\"] = df_paths_finished[\"path\"].str[0]\n",
    "df_paths_finished[\"target\"] = df_paths_finished[\"path\"].str[-1]\n",
    "df_paths_finished[\"isFinished\"] = True\n",
    "\n",
    "df_paths_unfinished[\"backclicks\"] = df_paths_unfinished[\"path\"].apply(lambda x: x.count(\"<\"))\n",
    "df_paths_unfinished[\"pathSteps\"] = df_paths_unfinished[\"path\"].apply(lambda x: x.count(\";\") + 1)\n",
    "df_paths_unfinished[\"uniqueArticles\"] = df_paths_unfinished[\"pathSteps\"] - df_paths_unfinished[\"backclicks\"]\n",
    "df_paths_unfinished[\"path\"] = df_paths_unfinished[\"path\"].apply(lambda x: x.split(\";\"))\n",
    "df_paths_unfinished[\"start\"] = df_paths_unfinished[\"path\"].str[0]\n",
    "df_paths_unfinished[\"isFinished\"] = False\n",
    "\n",
    "df_paths = pd.concat([df_paths_finished, df_paths_unfinished])\n",
    "display(df_paths.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles_all = pd.read_csv(\n",
    "    os.path.join(\"Data\", \"wikispeedia_paths-and-graph\", \"articles.tsv\"),\n",
    "    delimiter=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"name\"],\n",
    "    skip_blank_lines=True,\n",
    "    comment=\"#\",\n",
    "    encoding=\"UTF-8\"\n",
    ")\n",
    "\n",
    "display(df_articles_all.head())\n",
    "print(\"Size:\", df_articles_all.shape)\n",
    "\n",
    "shortest_paths = []\n",
    "with open(os.path.join(\"Data\", \"wikispeedia_paths-and-graph\", \"shortest-path-distance-matrix.txt\")) as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line == \"\" or line.startswith(\"#\"):\n",
    "            continue\n",
    "        shortest_paths.append(list(map(lambda x: -1 if x == \"_\" else int(x), list(line))))\n",
    "        \n",
    "shortest_paths = np.array(shortest_paths)\n",
    "\n",
    "df_shortest_paths = pd.DataFrame(shortest_paths, index=df_articles_all.name, columns=df_articles_all.name)\n",
    "\n",
    "display(df_shortest_paths.head())\n",
    "print(\"Size:\", df_shortest_paths.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_count_per_continent = df_continents.groupby(\"continent\").size().sort_values(ascending=False)\n",
    "\n",
    "display(article_count_per_continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continents_categories_counts = pd.crosstab(df_continents_categories[\"categoryMain\"], df_continents_categories[\"continent\"])\n",
    "\n",
    "display(df_continents_categories_counts)\n",
    "print(\"Size:\", df_continents_categories_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles_target = df_articles.copy()\n",
    "df_articles_target.columns = [column[0].upper() + column[1:] for column in df_articles_target.columns]\n",
    "df_articles_target = df_articles_target.add_prefix(\"target\")\n",
    "\n",
    "df_paths_articles = pd.merge(df_paths, df_articles_target, left_on=\"target\", right_on=\"targetArticle\", suffixes=[\"\", ]).drop(columns=\"targetArticle\")\n",
    "\n",
    "df_start_articles = df_articles.copy()\n",
    "df_start_articles.columns = [column[0].upper() + column[1:] for column in df_start_articles.columns]\n",
    "df_start_articles = df_start_articles.add_prefix(\"start\")\n",
    "df_paths_articles = pd.merge(df_paths_articles, df_start_articles, left_on=\"start\", right_on=\"startArticle\", suffixes=[\"\", ]).drop(columns=\"startArticle\")\n",
    "\n",
    "df_paths_articles[\"isFinishedInt\"] = df_paths_articles[\"isFinished\"].astype(int)\n",
    "\n",
    "display(df_paths_articles.head())\n",
    "print(\"Size:\", df_paths_articles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article_path_stats = pd.DataFrame()\n",
    "\n",
    "df_article_path_stats[\"article\"] = df_articles[\"article\"]\n",
    "df_article_path_stats[\"continent\"] = df_articles[\"continent\"]\n",
    "df_article_path_stats[\"targetFinished\"] = df_articles[\"article\"].map(df_paths_finished[\"target\"].value_counts()).fillna(0)\n",
    "df_article_path_stats[\"targetUnfinished\"] = df_articles[\"article\"].map(df_paths_unfinished[\"target\"].value_counts()).fillna(0)\n",
    "\n",
    "df_article_path_stats[\"startFinished\"] = df_articles[\"article\"].map(df_paths_finished[\"start\"].value_counts()).fillna(0)\n",
    "df_article_path_stats[\"startUnfinished\"] = df_articles[\"article\"].map(df_paths_unfinished[\"start\"].value_counts()).fillna(0)\n",
    "\n",
    "paths_finished = pd.Series(np.concatenate(df_paths_finished.path.values))\n",
    "paths_unfinished = pd.Series(np.concatenate(df_paths_unfinished.path.values))\n",
    "\n",
    "df_article_path_stats[\"anyFinished\"] = df_articles[\"article\"].map(paths_finished.value_counts()).fillna(0)\n",
    "df_article_path_stats[\"anyUnfinished\"] = df_articles[\"article\"].map(paths_unfinished.value_counts()).fillna(0)\n",
    "df_article_path_stats[\"anyPercentage\"] = (df_article_path_stats[\"anyFinished\"] + df_article_path_stats[\"anyUnfinished\"]) / (len(paths_finished) + len(paths_unfinished))\n",
    "\n",
    "display(df_article_path_stats.sort_values(\"anyPercentage\", ascending=False).head())\n",
    "print(\"Size:\", df_article_path_stats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df_paths_articles.copy()\n",
    "df_analysis = df_analysis.fillna(0)\n",
    "df_analysis[\"treatment\"] = df_analysis.targetContinent == \"Europe\"\n",
    "\n",
    "for col in [\"isFinishedInt\", \"durationInSec\", \"pathSteps\", \"rating\"]:\n",
    "    print(col, *scipy.stats.ttest_ind(df_analysis[df_analysis.treatment][col], df_analysis[~df_analysis.treatment][col], equal_var=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Story Plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
