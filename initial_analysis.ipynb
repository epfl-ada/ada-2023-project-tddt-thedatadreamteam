{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continents = pd.read_csv(\n",
    "    os.path.join(\"Data\", \"continents.csv\"), index_col=0\n",
    ")\n",
    "\n",
    "display(df_continents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors for all plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = df_continents['continent'].unique()\n",
    "random_colors = sns.color_palette('husl', n_colors=len(continents))\n",
    "continents_colors = {}\n",
    "for i in range(len(continents)):\n",
    "    continents_colors[continents[i]] = random_colors[i]\n",
    "print(continents_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles per continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents_grouped = df_continents.groupby(['continent']).size()\n",
    "continents_grouped = continents_grouped.sort_values(ascending=False)\n",
    "continents_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = len(continents_grouped.keys())\n",
    "random_colors = sns.color_palette('husl', n_colors=num_categories)\n",
    "ax = plt.bar(continents_grouped.keys(), continents_grouped.values, color = [continents_colors[continent] for continent in continents_grouped.keys()])\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.xlabel('Continent')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Categories by Continent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of articles by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.read_csv(\n",
    "    os.path.join(\"Data\", \"wikispeedia_paths-and-graph\", \"categories.tsv\"),\n",
    "    delimiter=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"article\", \"category\"],\n",
    "    skip_blank_lines=True,\n",
    "    comment=\"#\",\n",
    "    encoding=\"UTF-8\"\n",
    ")\n",
    "\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.merge(categories, df_continents, on=\"article\", how=\"inner\")\n",
    "articles = articles.fillna(\"\")\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cats = []\n",
    "for category in articles['category'].values:\n",
    "    main_cats.append(category.split('.')[1])\n",
    "\n",
    "articles['main_category'] = main_cats\n",
    "display(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_cat_continent = articles.groupby(['main_category','continent']).size()\n",
    "display(articles_cat_continent[('Geography','International')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have to check this plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_cat_continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = articles['main_category'].unique()\n",
    "continents = articles['continent'].unique()\n",
    "continents.sort()\n",
    "\n",
    "#In case we do not want international\n",
    "mask = (continents != 'International')\n",
    "continents = continents[mask]\n",
    "\n",
    "category_positions = np.arange(len(categories))\n",
    "bar_width = 0.5\n",
    "\n",
    "continents_values = {}\n",
    "for i, continent in enumerate(continents):\n",
    "    frequencies = []\n",
    "    for category in categories:\n",
    "        try:\n",
    "            value = articles_cat_continent[(category,continent)]\n",
    "        except KeyError:\n",
    "            value = 0\n",
    "        frequencies.append(value)\n",
    "    continents_values[continent] = frequencies\n",
    "\n",
    "df_continent_frequencies = pd.DataFrame(continents_values).T\n",
    "df_continent_frequencies.columns = categories\n",
    "display(df_continent_frequencies)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bottom = np.zeros(len(categories))\n",
    "\n",
    "for continent in continents:\n",
    "    ax.barh(categories, continents_values[continent], label=continent, color=continents_colors[continent], edgecolor='w', height=0.5, left=bottom)\n",
    "    bottom += continents_values[continent]\n",
    "\n",
    "ax.set_yticks(category_positions)\n",
    "ax.set_yticklabels(categories)\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Category')\n",
    "plt.title('Frequency of Continents in Each Category')\n",
    "\n",
    "# Display legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = pd.read_csv(\"Data/wikispeedia_paths-and-graph/articles.tsv\", sep=\"\\t\",header=None, names=[\"article\"], skiprows=11)\n",
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the length and create a new dataframe called analysis_df to be used during the initial analysis\n",
    "\n",
    "analysis_df = articles_df.copy()\n",
    "\n",
    "# Specify the path to the folder containing the .txt files\n",
    "plaintext_path = 'data/plaintext_articles'\n",
    "\n",
    "# Create an empty list to store the results\n",
    "word_counts = []\n",
    "\n",
    "# Iterate through each article in the articles.tsv file\n",
    "for index, row in analysis_df.iterrows():\n",
    "    # Construct the full path to the .txt file\n",
    "    file_path = os.path.join(plaintext_path, row['article'] + '.txt')\n",
    "\n",
    "    # Read the contents of the .txt file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "\n",
    "        _ = file.readline() # Skip the first line because it contains the word #copyright\n",
    "        content = file.read()\n",
    "\n",
    "    # Count the number of words in the article\n",
    "    word_count = len(content.split())\n",
    "\n",
    "    # Append the result to the list\n",
    "    word_counts.append(word_count)\n",
    "\n",
    "# Add a new column 'WordCount' to the analysis_df\n",
    "analysis_df['length'] = word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(analysis_df.head())\n",
    "print(analysis_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge analysis with continents\n",
    "analysis_df = pd.merge(analysis_df, df_continents, on=[\"article\"])\n",
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the average length of article for each continent\n",
    "continent_length = analysis_df.groupby(['continent']).mean('length')\n",
    "continent_length=continent_length.sort_values('length',ascending=False)\n",
    "continent_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.bar(continent_length.index,continent_length.values.reshape(8) , color = [continents_colors[continent] for continent in continent_length.index])\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.xlabel('Continent')\n",
    "plt.ylabel('Length')\n",
    "plt.title('Average length of articles by continent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pagerank\n",
    "pagerank_df = pd.read_csv(\"Data/pagerank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pagerank_df.head())\n",
    "print(pagerank_df.shape)\n",
    "print(\"Note that the pageRank has less rows!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.merge(analysis_df, pagerank_df, left_on=[\"article\"], right_on=[\"Articles\"], how=\"left\").fillna(0)\n",
    "analysis_df = analysis_df.drop([\"Articles\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(analysis_df.head())\n",
    "analysis_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean\n",
    "mean_pagerank_continent = analysis_df.groupby(\"continent\").mean(\"PageRank\")\n",
    "mean_pagerank_continent =mean_pagerank_continent.sort_values(by='PageRank', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.bar(mean_pagerank_continent.index,mean_pagerank_continent['PageRank'] , color = [continents_colors[continent] for continent in mean_pagerank_continent.index])\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.xlabel('Continent')\n",
    "plt.ylabel('Pagerank')\n",
    "plt.title('Average PageRank by continent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group paths by continents, one path will be assigned to the continent corresponding to the GOAL article\n",
    "\n",
    "Compute the number of \"backclicks\" in each path\n",
    "\n",
    "Compute the length of each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished_df = pd.read_csv(\"Data/wikispeedia_paths-and-graph/paths_finished.tsv\", sep=\"\\t\", header=None, names = [\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"rating\"], skiprows=16)\n",
    "paths_unfinished_df = pd.read_csv(\"Data/wikispeedia_paths-and-graph/paths_unfinished.tsv\", sep=\"\\t\", header=None, names = [\"hashedIpAddress\",\"timestamp\",\"durationInSec\", \"unf_path\", \"target\",\"motif\"],skiprows=17)\n",
    "\n",
    "# Extract the target article from finished paths\n",
    "paths_finished_df[\"target\"] = paths_finished_df['path'].apply(lambda x: x.split(';')[-1])\n",
    "\n",
    "# Count the number of backclicks\n",
    "paths_finished_df['backclicks'] = paths_finished_df['path'].apply(lambda x: x.count('<'))\n",
    "paths_unfinished_df['backclicks'] = paths_unfinished_df['unf_path'].apply(lambda x: x.count('<'))\n",
    "\n",
    "# Compute the length of each path\n",
    "paths_finished_df['path_steps'] = paths_finished_df['path'].apply(lambda x: x.count(';') + 1 + x.count('<'))\n",
    "paths_unfinished_df['path_steps'] = paths_unfinished_df['unf_path'].apply(lambda x: x.count(';') + 1 + x.count('<'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the paths with the continents\n",
    "\n",
    "analysis_fin_paths = pd.merge(paths_finished_df, df_continents, left_on=\"target\", right_on=\"article\").drop(\"article\", axis=1)\n",
    "analysis_unf_paths = pd.merge(paths_unfinished_df, df_continents, left_on=\"target\", right_on=\"article\").drop(\"article\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(analysis_fin_paths.head())\n",
    "print(analysis_fin_paths.shape)\n",
    "\n",
    "display(analysis_unf_paths.head())\n",
    "print(analysis_unf_paths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_data = pd.DataFrame()\n",
    "\n",
    "continent_data[\"av_pagerank\"] = mean_pagerank_continent['PageRank']\n",
    "\n",
    "# Create columns for av. backclicks\n",
    "continent_data[\"av_fin_backcliks\"] =  analysis_fin_paths.groupby(\"continent\")[\"backclicks\"].mean()\n",
    "continent_data[\"av_unf_backcliks\"] =  analysis_unf_paths.groupby(\"continent\")[\"backclicks\"].mean()\n",
    "\n",
    "# Create columns for av. path steps\n",
    "continent_data[\"av_fin_steps\"] =  analysis_fin_paths.groupby(\"continent\")[\"path_steps\"].mean()\n",
    "continent_data[\"av_unf_steps\"] =  analysis_unf_paths.groupby(\"continent\")[\"path_steps\"].mean()\n",
    "\n",
    "# Create columns for the number of finished and unfinished paths for each continent\n",
    "continent_data[\"fin_paths\"] = analysis_fin_paths[\"continent\"].value_counts()\n",
    "continent_data[\"unf_paths\"] = analysis_unf_paths[\"continent\"].value_counts()\n",
    "continent_data['per_fin_paths'] = (continent_data[\"fin_paths\"]/(continent_data[\"fin_paths\"]+continent_data[\"unf_paths\"]))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_data=continent_data.sort_values(by='per_fin_paths',ascending=False)\n",
    "display(continent_data)\n",
    "print(continent_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.bar(continent_data.index,continent_data['per_fin_paths'] , color = [continents_colors[continent] for continent in continent_data.index])\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.xlabel('Continent')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Percentage of finished paths by continent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_paths = len(paths_finished_df) + len(paths_unfinished_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns to count the number of times each article appears as goal in finished and unfinished paths\n",
    "analysis_df[\"n_as_goal_in_fin\"] = analysis_df[\"article\"].map(analysis_fin_paths[\"target\"].value_counts()).fillna(0)\n",
    "analysis_df[\"n_as_goal_in_unf\"] = analysis_df[\"article\"].map(analysis_unf_paths[\"target\"].value_counts()).fillna(0)\n",
    "\n",
    "# Create columns to count the number of times each article appears in general in finished and unfinished paths\n",
    "analysis_df[\"n_in_fin_paths\"] = analysis_df[\"article\"].map(pd.Series(';'.join(analysis_fin_paths['path']).split(';')).value_counts()).fillna(0)\n",
    "analysis_df[\"n_in_unf_paths\"] = analysis_df[\"article\"].map(pd.Series(';'.join(analysis_unf_paths['unf_path']).split(';')).value_counts()).fillna(0)\n",
    "\n",
    "#Let's calculate the probability of finding an article (we can compare this with the pagerank)\n",
    "analysis_df[\"prob_finding\"] = (analysis_df[\"n_in_fin_paths\"] + analysis_df[\"n_in_unf_paths\"])/total_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(analysis_df)\n",
    "print(analysis_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: Some plots\n",
    "# Show the frequency of the articles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
